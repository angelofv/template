# Template â€“Â MLÂ PipelineÂ Starter

[![CI](https://github.com/angelofv/template/actions/workflows/ci.yml/badge.svg)](https://github.com/angelofv/template/actions/workflows/ci.yml)
[![CD](https://github.com/angelofv/template/actions/workflows/cd.yml/badge.svg)](https://github.com/angelofv/template/actions/workflows/cd.yml)
[![codecov](https://codecov.io/gh/angelofv/template/graph/badge.svg?token=RD0GRZMER0)](https://codecov.io/gh/angelofv/template)

> **A readyâ€‘toâ€‘use scaffold for building, tracking, and deploying small machineâ€‘learning projects.**
>
> MixÂ &Â match **PrefectÂ 3** flows, **MLflow** tracking, **Kedro** data catalogues, **FastAPI** microâ€‘services, and **Streamlit** demosâ€¯â€”â€¯all shipped in reproducible **Docker** images and guarded by GitHubÂ Actions **CIâ€¯/â€¯CD**.

---

## âœ¨Â Highlights

| Capability          | Whatâ€™s inside                   | Why care?                                                            |
| ------------------- | ------------------------------- | -------------------------------------------------------------------- |
| Orchestration       | PrefectÂ 3 `@flow` tasks         | Dependency graph, logs, retries & scheduling **without extra infra** |
| Experiment tracking | MLflow *file store* (local)     | Compare runs; rich UI served on portâ€¯`5000`                          |
| Data layer          | Kedro `DataCatalog`             | Declarative datasets (CSV, Parquet, Pickleâ€¯â€¦)                        |
| Serving             | FastAPIÂ (+â€¯uvicorn) & Streamlit | From REST inference to an interactive playground                     |
| Dev ergonomics      | Makefile, Ruff, Conda, Docker   | Oneâ€‘liners & consistent environments                                 |
| Quality gates       | pytestâ€‘cov, Ruff, Codecov badge | Keep techâ€‘debt under control                                         |
| CIâ€¯/â€¯CD             | GitHubÂ ActionsÂ â‡†Â GHCR + Trivy   | Pushâ€‘toâ€‘image pipeline with security scans                           |

---

## âš¡Â Quickâ€‘start

### 0.â€¯Prerequisites

* **PythonÂ 3.10+**
* **DockerÂ Desktop** (or Podman/Colima)
* (optional) **Conda**Â â‰¥â€¯4.10
* **Codecov** â€“ create a free account, enable your repository, and add a `CODECOV_TOKEN` secret under **Settingsâ€¯â†’â€¯Secretsâ€¯â†’â€¯Actions**.

### 1â€‘A.â€¯Local workflow (no Docker)

```bash
make create_env          # oneâ€‘shot Conda env â€˜templateâ€™
conda activate template
make requirements        # install Python deps

make local-infra         # spin up MLflowÂ :5000 + PrefectÂ :4200
make local-pipeline      # run the full flow
make local-serve         # start APIÂ :8000 + StreamlitÂ :8501
# â€¦ hack, commit, profit! â€¦
make local-down          # stop all local services
```

### 1â€‘B.â€¯Dockerâ€‘first workflow

```bash
make infra      # spin up MLflow + Prefect in containers
make pipeline   # build pipeline image & run full flow
make serve      # build & start API + Streamlit

# Tearâ€‘down
make down
```

<details>
<summary>TL;DR</summary>

```bash
docker compose up --build
```

`docker compose` will launch *everything*, but you will lose the pretty, colourâ€‘coded logs provided by the MakefileÂ ğŸ™ƒ.

</details>

---

## ğŸ› ï¸Â Everyâ€‘day commands

| Command                                                        | Purpose                                   |
| -------------------------------------------------------------- | ----------------------------------------- |
| `make format`                                                  | Autoâ€‘format the whole codeâ€‘base with Ruff |
| `make lint`                                                    | Static analysis                           |
| `make test`                                                    | pytest + coverage                         |
| `make clean`                                                   | Remove Python artifacts & caches          |
| `make mlflow-clean`                                            | Wipe local `mlruns/` folder               |
| `make infra / pipeline / serve / down`                         | **Docker** helpers                        |
| `make local-infra / local-pipeline / local-serve / local-down` | **Local** helpers                         |

Run `make help` to list every available target and its description.

---

## ğŸ§ªÂ Running tests locally

Tests require the repository root on **PYTHONPATH** so that `import src` resolves.

```bash
make test
```

If you must, run manually:

```bash
python -m pytest -q
```

---

## ğŸ“¦Â CIÂ /Â CD pipeline (GitHubÂ Actions)

* **ci.yml** â€“ on every push / PR
  1.â€¯Set up Python & cache pip
  2.â€¯`make lint` & `make test`
  3.â€¯Upload coverage to Codecov
* **cd.yml** â€“ after a successful CI
  1.â€¯Build a multiâ€‘stage image & push to **GHCR** (`:latest`â€¯+â€¯SHA)
  2.â€¯Scan with **Trivy** (fail on critical / high vulnerabilities)
  3.â€¯Run a smoke test (`import src`) inside the container

Badges at the top of this file always reflect the latest run.

---

## ğŸ—‚Â Project layout

```
â”œâ”€â”€ README.md
â”œâ”€â”€ Dockerfile             # Multiâ€‘stage build (pipeline / api / app)
â”œâ”€â”€ docker-compose.yaml    # Local orchestration
â”œâ”€â”€ Makefile               # Dev helpers
â”œâ”€â”€ pyproject.toml         # Project metadata (PEPÂ 621)
â”œâ”€â”€ requirements.txt       # Runtime + dev Python deps
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ configs/               # Global YAML config + Kedro DataCatalog
â”‚   â”œâ”€â”€ catalog.yaml
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ data/                  # 01_raw / 02_processed / 03_models / 04_reports
â”œâ”€â”€ notebooks/             # Exploratory notebooks (ignored by Docker)
â”‚Â Â  â””â”€â”€ 00_exploration.ipynb
â”œâ”€â”€ app/              # Userâ€‘facing layers
â”‚Â Â  â”œâ”€â”€ api.py             # FastAPI inference service
â”‚Â Â  â””â”€â”€ app.py             # Streamlit demo UI
â”œâ”€â”€ src/                   # Pipeline code (Prefect flows, modelling, utils)
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ config.py
â”‚Â Â  â”œâ”€â”€ extract.py
â”‚Â Â  â”œâ”€â”€ train.py
â”‚Â Â  â”œâ”€â”€ plot_metrics.py
â”‚Â Â  â””â”€â”€ run.py
â”œâ”€â”€ tests/                 # Unit & smoke tests
â”‚Â Â  â”œâ”€â”€ test_modeling.py
â”‚Â Â  â”œâ”€â”€ test_plotting.py
â”‚Â Â  â”œâ”€â”€ test_preprocessing.py
â”‚Â Â  â”œâ”€â”€ test_services.py
â”‚Â Â  â””â”€â”€ .coveragerc
â””â”€â”€ .github/workflows/     # CIâ€¯/â€¯CD definitions
    â”œâ”€â”€ ci.yml
    â””â”€â”€ cd.yml
```

---

## âš™ï¸Â Configuration

All pipeline tunables live in a single YAML file:

| File                  | Consumed by                            | Notes               |
| --------------------- | -------------------------------------- | ------------------- |
| `configs/config.yaml` | every Prefect task via `load_config()` | See `src/config.py` |

The Kedro **DataCatalog** is defined in `configs/catalog.yaml`.

---

## ğŸ—ï¸Â Extending

1. **Change the model** â€“ edit `train_model()` and add hyperâ€‘params to `config.yaml`.
2. **Add new tasks** â€“ write a Prefect `@flow` function and wire it up in `src/run.py`.
3. **Ship notebooks** â€“ mount them inside the image or copy them in the `Dockerfile` when needed.
4. **Deploy** â€“ pull `ghcr.io/<user>/template:<tag>` on any container platform.

---

## ğŸ“œÂ License

Released under the **MIT License** â€“ see [`LICENSE`](LICENSE) for details.
