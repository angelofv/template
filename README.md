# Template â€“Â MLÂ PipelineÂ Starter

[![CI](https://github.com/angelofv/template/actions/workflows/ci.yml/badge.svg)](https://github.com/angelofv/template/actions/workflows/ci.yml)
[![CD](https://github.com/angelofv/template/actions/workflows/cd.yml/badge.svg)](https://github.com/angelofv/template/actions/workflows/cd.yml)
[![codecov](https://codecov.io/gh/angelofv/template/graph/badge.svg?token=RD0GRZMER0)](https://codecov.io/gh/angelofv/template)

> **A ready-to-use template for building, tracking and deploying your machine-learning side-projects.**
>
> MixÂ &Â match **PrefectÂ 3**Â flows, **MLflow**Â tracking, **Kedro** dataâ€‘catalogs, **FastAPI** microâ€‘services, **Streamlit** demos, all shipped in reproducible **Docker** images and guarded by GitHubÂ Actions **CIÂ â†”Â CD**.

---

## âœ¨Â Highlights

| Â CapabilityÂ Â Â Â Â Â Â Â Â Â Â  | Â Whatâ€™s inside                  | Â Why care?                                                   |
| ---------------------- | ------------------------------- | ------------------------------------------------------------ |
| Orchestration          | PrefectÂ 3 `@flow` tasks         | Dependency graph, logs, retries & scheduling with zero infra |
| Experiment tracking    | MLflow fileâ€‘store (local)       | Tracking experiments, UI at `:5000`                          |
| Data management        | Kedro `DataCatalog`             | Declarative dataset layer (CSV, Parquet, Pickleâ€¦)            |
| Serving                | FastAPIÂ (+Â uvicorn) & Streamlit | From REST inference to interactive demo                      |
| Dev ergonomics         | Makefile, Ruff, Conda, Docker   | Oneâ€‘liners & consistent environments                         |
| Quality gates          | pytestâ€‘cov, Ruff, Codecov badge | Keep tech debt under control                                 |
| CIÂ /Â CD                | GHÂ Actions ğŸ” GHCR + Trivy      | Pushâ€‘toâ€‘image pipeline with security scan                    |

---
> **Heads-up ğŸ–¼ï¸**
> The Streamlit dashboard is a template.  
> Personalise it by editing `services/app/app.py` **or** by exporting environment
> variables such as `PROFILE_NAME`, `PROFILE_DESC`, `PROFILE_AVATAR`, `LINK_GITHUB`, etc.

## âš¡Â QuickÂ start

### 0.Â Prerequisites

* **PythonÂ 3.10+**
* **DockerÂ Desktop**
* (optional) **Conda** â‰¥Â 4.10
* **Codecov** â€“ create a free account at [Codecov](https://codecov.io/), enable your repository there, then add the resulting `CODECOV_TOKEN` as a secret in your GitHub repository settings.

### 1.Â OptionÂ A â€“Â Native (no Docker)

```bash
make create_environment   # conda env â€˜templateâ€™ (1Ã—)
conda activate template
make requirements         # pip install (1Ã—)

make local-infra          # spin up MLflow (5000) + Prefect (4200)
make local-pipeline       # run full flow
make local-serve          # spin up API (8000) + Streamlit (8501)
# â€¦ hack, commit, profit! â€¦
make local-down           # stop all local services
```

### 1.Â OptionÂ B â€“Â Dockerâ€‘first

```bash
make infra     # pull & spin up MLflow (5000) + Prefect (4200)
make pipeline  # build pipeline image & run full flow
make serve     # build & spin up API (8000) + Streamlit app (8501)

# same ports as native; tearâ€‘down:
make down
```

> **TL;DR** â€“ `docker compose up --build` launches *everything* at once (but loses the nice logs & coloured prompts our Makefile gives ğŸ™ƒ).

---

## ğŸ› ï¸Â Everyâ€‘day commands

| Command                                                        | Purpose                          |
| --------------------------------------                         | -------------------------------- |
| `make format`                                                  | Ruffâ€‘format the entire codeâ€‘base |
| `make lint`                                                    | Ruff static analysis             |
| `make test`                                                    | pytest + coverage XML (Codecov)  |
| `make clean`                                                   | remove Python artefacts & caches |
| `make mlflow-clean`                                            | wipe local `mlruns/` folder      |
| `make infra / pipeline / serve / down`                         | Docker workflow helpers          |
| `make local-infra / local-pipeline / local-serve / local-down` | Local workflow helpers           |
---
> **Tip:** run `make help` to see *all* available targets and their descriptions.

## ğŸ§ªÂ Running tests locally

The tests expect the repo root to be on **PYTHONPATH** so that `import src` and `import services` resolve. Two paths:

1. **Use Makefile** (recommended) â€“ already sets the env var:

   ```bash
   make test          # ğŸš¦ all green
   ```
2. **Manual run** â€“ export once per shell:

   ```bash
   export PYTHONPATH="$PWD:$PYTHONPATH"
   pytest -q          #   <1â€¯s
   ```

> Got `ModuleNotFoundError: src`? You probably ran `pytest` from a parent directory **or** forgot the `PYTHONPATH` export.

---

## ğŸ“¦Â CIÂ /Â CD pipeline (GitHubÂ Actions)

* **CIÂ workflow**Â `ci.yml` â€“ on every push / PR
  1.Â Setâ€‘up Python, cache pip.
  2.Â Install deps; run `make lint` & `make test`.
  3.Â Upload coverage to Codecov.
* **CDÂ workflow**Â `cd.yml` â€“ after successful CI
  1.Â Build multiâ€‘stage image; push to **GHCR** (`:latest` + SHA).
  2.Â Scan with **Trivy** (fail on critical/high vulns).
  3.Â Spinâ€‘up container & import package as smoke test.

Badges at the top of this file reflect the latest run status.

---

## ğŸ—‚Â ProjectÂ layout

```
â”œâ”€â”€ src/            # Prefect tasks, model, plots
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ modeling/
â”‚   â”œâ”€â”€ plotting/
â”‚   â””â”€â”€ run.py
â”œâ”€â”€ services/       # API (FastAPI) + frontend (Streamlit)
â”‚   â”œâ”€â”€ api/
â”‚   â””â”€â”€ app/
â”œâ”€â”€ configs/        # YAML configs + Kedro catalog
â”œâ”€â”€ data/           # 01_raw / 02_processed / 03_models / 04_reports
â”œâ”€â”€ notebooks/      # Exploratory stuff (ignored by Dockerfile)
â”œâ”€â”€ Dockerfile      # Pipeline image (multiâ€‘stage)
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ Makefile        # Dev utilities
â””â”€â”€ tests/          # tiny unit + smoke suite
```

---

## âš™ï¸Â Configuration

| File                         | Consumed by                    | Notes                     |
| ---------------------------- | ------------------------------ | ------------------------- |
| `configs/preprocessing.yaml` | `src.preprocessing.preprocess` | adjust cleaning steps     |
| `configs/modeling.yaml`      | `src.modeling.train_model`     | hyperâ€‘parameters          |
| `configs/plotting.yaml`      | `src.plotting.plot_metrics`    | figure tuning             |
| `configs/catalog.yaml`       | Kedro `DataCatalog`            | logical names â†” artefacts |

Override any path by exporting env vars `PREPROCESSING_CONFIG`, `MODELING_CONFIG`, â€¦ (see `src/config.py`).

---

## ğŸŒÂ Environment variables

All tasks read their configuration from **environment variables** first, then fall back to sane defaults. (Optional) Create a `.env` file at the repo root or export them in your shell.

| Variable                                         | Default                      | Component          | Purpose                                                                                        |
| ------------------------------------------------ | ---------------------------- | ------------------ | ---------------------------------------------------------------------------------------------- |
| `MLFLOW_TRACKING_URI`                            | `file:./mlruns`              | pipeline, API      | Where MLflow stores runs & artefacts (set to `http://host.docker.internal:5000` inside Docker) |
| `MLFLOW_EXPERIMENT`                              | `Default`                    | pipeline           | MLflow experiment name                                                                         |
| `PREFECT_API_URL`                                | `http://localhost:4200/api`  | pipeline           | Connect Prefect client to a remote server (`http://localhost:4200/api`)   |
| `PREPROCESSING_CONFIG`                           | `configs/preprocessing.yaml` | pipeline           | Custom YAML for cleaning steps                                                                 |
| `MODELING_CONFIG`                                | `configs/modeling.yaml`      | pipeline           | Hyperâ€‘parameters YAML                                                                          |
| `PLOTTING_CONFIG`                                | `configs/plotting.yaml`      | pipeline           | Plot options YAML                                                                              |
| `MODEL_PATH`                                     | `data/03_models/model.pkl`   | FastAPI, Streamlit | Location of the pickled model used for inference                                               |
| `API_URL`                                        | `http://localhost:8000`      | Streamlit          | Endpoint for prediction requests                                                               |
| `PROFILE_NAME`, `PROFILE_DESC`, `PROFILE_LOC`, â€¦ | â€“                            | Streamlit          | Sidebar personalisation (avatar, links)                                                        |

---

## ğŸ—ï¸Â Extending

1. **Swap model** â€“ edit `train_model()`; update config.
2. **Add task** â€“ new `@flow` in appropriate module; wire in `src/run.py`.
3. **Ship notebooks** â€“ mount inside the image or add to `Dockerfile` if you really need them.
4. **Deploy** â€“ pull `ghcr.io/<user>/template:<tag>` on any container platform.

---

## ğŸ“œÂ License

Released under the **MIT License**. See [`LICENSE`](LICENSE) for full text.

