services:
  # ───────────────── MLflow UI (file-store) ─────────────────
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    command:
      - mlflow
      - server
      - --backend-store-uri
      - /mlruns
      - --artifacts-destination
      - /mlruns
      - --serve-artifacts
      - --host
      - 0.0.0.0
      - --port
      - "5000"
    ports:
      - "5000:5000"
    volumes:
      - mlflow_runs:/mlruns   # runs + artefacts

  # ───────────────── Prefect Server ─────────────────
  prefect:
    image: prefecthq/prefect:3-latest
    command:
      - prefect
      - server
      - start
      - --host
      - 0.0.0.0
      - --port
      - "4200"
    ports:
      - "4200:4200"
    volumes:
      - prefect_home:/home/app/.prefect

  # ─────────────── ML Pipeline ───────────────
  pipeline:
    build: .
    depends_on:
      mlflow:
        condition: service_started
      prefect:
        condition: service_started
    extra_hosts:
      - "host.docker.internal:host-gateway"
    command:
      - python
      - -m
      - src.run
    volumes:
      - .:/opt/app
      - mlflow_runs:/opt/app/mlruns
    environment:
      MLFLOW_TRACKING_URI:    http://host.docker.internal:5000
      PREFECT_API_URL:        http://host.docker.internal:4200/api
      PYTHONUNBUFFERED:       "1"
      PREFECT_LOGGING_LEVEL:  INFO
      RICH_FORCE_TERMINAL:    "1"
      TERM:                   xterm-256color
      FORCE_COLOR:            "1"
  api:
    build:
      context: .
      dockerfile: services/api/Dockerfile
    ports:
      - "8000:8000"
    depends_on:
      - mlflow
    environment:
      MODEL_PATH: /app/data/03_models/model.pkl
    volumes:
      - ./data/03_models:/app/data/03_models:ro
  app:
    build:
      context: .
      dockerfile: services/app/Dockerfile
    ports:
      - "8501:8501"
    depends_on:
      - api
    environment:
      API_URL: http://api:8000

volumes:
  mlflow_runs:
  prefect_home:
